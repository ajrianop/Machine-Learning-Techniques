{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaaMKOHcA/PAWZYZalVWeg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajrianop/Machine-Learning-Techniques/blob/main/02_K_fold_Cross_Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cross Validation**"
      ],
      "metadata": {
        "id": "6phDuQM79FqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross validation is a technique used in machine learning to assess how well a trained model will generalize to an independent data set. It's particularly helpful when you have a limited amount of data.\n",
        "\n",
        "In this notebook, we are going to work with one of the common types of cross-validation, which is K-fold cross-validation. The idea is to provide an explanation of the technique step by step and use Python code for better understanding\n",
        "\n",
        "**How is it works?**\n",
        "In order to apply the K-fold technique, we follow the next steps:\n",
        "\n",
        "* Splits the train subset into K-randomly assigned segments.\n",
        "* Consider one segment as the **test data**. And the other K-1 segments as the **train data**.\n",
        "* Train the model with the K-1 segments and measure their performance for each segment.\n",
        "* Repeat this with each of the K-1 segments.\n",
        "* To obtain a performance score, take the average of the K-1 r-squared errors.\n",
        "\n",
        "**What is the idea with this technique?**\n",
        "\n",
        "Cross-validation helps to provide a more accurate estimate of a model's performance by using multiple splits of the data, reducing the risk of overfitting to a particular training-validation split.\n",
        "\n",
        "**In practice:** In K-fold cross-validation, we repeatedly split the data into K subsets (folds), where each fold serves as both a training set and a test set. By doing this repeatedly with different splits of the data, we can assess how well the model performs on average across various subsets of the data. This helps us obtain a more reliable estimate of the model's performance and enables us to choose the model variation that performs the best on average."
      ],
      "metadata": {
        "id": "fxwJicRr9L6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Example:**\n",
        "Consider the iris flower dataset. We are going to see only the perform of the results"
      ],
      "metadata": {
        "id": "JLGUQAA-EUSm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JnqqwQ_59D4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "\n",
        "iris = datasets.load_iris()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to assess the performance of Support Vector Classification (SVC) using K-fold cross-validation, we will first employ the conventional train-test split method to train the SVC model and evaluate its performance. Subsequently, we will utilize the K-fold technique to conduct a similar evaluation and compare the results. This comparative analysis will provide insights into the effectiveness of different evaluation approaches for SVC."
      ],
      "metadata": {
        "id": "m6Y8_fq_Ix8a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Using the conventional method train/test split***"
      ],
      "metadata": {
        "id": "aeoeY-PUXpI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the complete iris dataset with a train/test sets with 30% to test and 70% to train\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=0)\n",
        "\n",
        "# Using training set to build an SVC model for classification\n",
        "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
        "\n",
        "# The performance score with the test data can be seen using model.score(X_test, y_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBhvEsOMJTBC",
        "outputId": "585430b3-765d-4169-b3d4-a23ccc644170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9777777777777777"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Using K-fold cross validation method train/test split***"
      ],
      "metadata": {
        "id": "xdiQ4n6jXx12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To see the scores of the previous model using now cross validation, we use cross_val_score\n",
        "scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",
        "\n",
        "# Print the accuracy for each fold\n",
        "print(scores)\n",
        "\n",
        "# And the mean accuracy of all 4 folds\n",
        "print(scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbIhF5DCWsBI",
        "outputId": "af81a599-bb12-49f8-8b01-373e8b7ae071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.96666667 1.         0.96666667 0.96666667 1.        ]\n",
            "0.9800000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let us describe the perform to some different numbers of folds:"
      ],
      "metadata": {
        "id": "8fYZSiCTYhhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validation(model, number_of_folds):\n",
        "  # Define the cross validation function\n",
        "  scores = cross_val_score(model, iris.data, iris.target, cv=number_of_folds)\n",
        "  print(f'Accuracy for each fold\\n   {scores}\\n')\n",
        "  # And the mean accuracy of all k folds\n",
        "  print(f'The mean of all K-folds\\n   {scores.mean()}')"
      ],
      "metadata": {
        "id": "R5bRK9tWWsEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = clf\n",
        "for number_of_folds in range(3,8):\n",
        "  print(f'K-fold cross validation for K={number_of_folds} folds')\n",
        "  cross_validation(model , number_of_folds)\n",
        "  print('-----------------------\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwFAvTA_ZGzd",
        "outputId": "71dbd1b9-93ca-4ace-9dc6-d93cfb8e5622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-fold cross validation for K=3 folds\n",
            "Accuracy for each fold\n",
            "   [1.   1.   0.98]\n",
            "\n",
            "The mean of all K-folds\n",
            "   0.9933333333333333\n",
            "-----------------------\n",
            "\n",
            "K-fold cross validation for K=4 folds\n",
            "Accuracy for each fold\n",
            "   [1.         0.97368421 0.97297297 0.97297297]\n",
            "\n",
            "The mean of all K-folds\n",
            "   0.9799075391180654\n",
            "-----------------------\n",
            "\n",
            "K-fold cross validation for K=5 folds\n",
            "Accuracy for each fold\n",
            "   [0.96666667 1.         0.96666667 0.96666667 1.        ]\n",
            "\n",
            "The mean of all K-folds\n",
            "   0.9800000000000001\n",
            "-----------------------\n",
            "\n",
            "K-fold cross validation for K=6 folds\n",
            "Accuracy for each fold\n",
            "   [0.96 1.   0.96 0.96 1.   1.  ]\n",
            "\n",
            "The mean of all K-folds\n",
            "   0.98\n",
            "-----------------------\n",
            "\n",
            "K-fold cross validation for K=7 folds\n",
            "Accuracy for each fold\n",
            "   [0.95454545 1.         0.95454545 0.95238095 0.95238095 1.\n",
            " 1.        ]\n",
            "\n",
            "The mean of all K-folds\n",
            "   0.9734075448361164\n",
            "-----------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, the best description is given by the K = 5 folds. Using the linear Kernel in SVC."
      ],
      "metadata": {
        "id": "1OFSoNFWa9YY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Using different Kernel in SVC to see the performance of the model**"
      ],
      "metadata": {
        "id": "6TWPhKRMHcMo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Using the conventional method train/test split***"
      ],
      "metadata": {
        "id": "Pk2wtteuwn29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we see the performance using the SVC with polynomial kernel with degree 3 (by default)."
      ],
      "metadata": {
        "id": "jyguPzmAytFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using training set to build an SVC model with polynomial kernel (degree by default is 3) for classification\n",
        "clf_poly = svm.SVC(kernel='poly', C=1).fit(X_train, y_train)\n",
        "\n",
        "# The performance score with the test data can be seen using model.score(X_test, y_test)\n",
        "clf_poly.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwRUyjxqwuDV",
        "outputId": "12f9c231-3afd-42ee-edea-1fb12b171dbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9777777777777777"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Using K-fold cross validation method train/test split***"
      ],
      "metadata": {
        "id": "J6d3Np43aLyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the polynomial Kernel\n",
        "model_poly = clf_poly\n",
        "for number_of_folds in range(3,8):\n",
        "  print(f'K-fold cross validation for K={number_of_folds} folds')\n",
        "  cross_validation(model_poly , number_of_folds)\n",
        "  print('-----------------------\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGDpUKmOHOPi",
        "outputId": "1f10507c-d37d-4b05-d394-0b5a4638d3a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-fold cross validation for K=3 folds\n",
            "Accuracy for each fold\n",
            "   [0.98 0.94 0.98]\n",
            "\n",
            "The mean of all K-folds\n",
            "   0.9666666666666667\n",
            "-----------------------\n",
            "\n",
            "K-fold cross validation for K=4 folds\n",
            "Accuracy for each fold\n",
            "   [0.97368421 0.94736842 0.97297297 1.        ]\n",
            "\n",
            "The mean of all K-folds\n",
            "   0.9735064011379801\n",
            "-----------------------\n",
            "\n",
            "K-fold cross validation for K=5 folds\n",
            "Accuracy for each fold\n",
            "   [0.96666667 1.         0.96666667 0.96666667 1.        ]\n",
            "\n",
            "The mean of all K-folds\n",
            "   0.9800000000000001\n",
            "-----------------------\n",
            "\n",
            "K-fold cross validation for K=6 folds\n",
            "Accuracy for each fold\n",
            "   [0.96 1.   0.92 0.92 0.96 1.  ]\n",
            "\n",
            "The mean of all K-folds\n",
            "   0.96\n",
            "-----------------------\n",
            "\n",
            "K-fold cross validation for K=7 folds\n",
            "Accuracy for each fold\n",
            "   [0.95454545 1.         0.95454545 0.9047619  0.95238095 1.\n",
            " 1.        ]\n",
            "\n",
            "The mean of all K-folds\n",
            "   0.9666048237476809\n",
            "-----------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **What happens if we change the degree of the polynomial kernel?**"
      ],
      "metadata": {
        "id": "OSYuWq7UzAz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the degree\n",
        "degree = 2\n",
        "\n",
        "# Using training set to build an SVC model with polynomial kernel (degree by default is 3) for classification\n",
        "clf_poly = svm.SVC(kernel='poly', degree = degree, C=1).fit(X_train, y_train)\n",
        "\n",
        "# The performance score with the test data can be seen using model.score(X_test, y_test)\n",
        "clf_poly.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4zcI1LwzV7z",
        "outputId": "6a0b96bd-c6eb-4eea-cd44-19bf9574cb0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9777777777777777"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using training set to build an SVC model with polynomial kernel (degree by default is 3) for classification\n",
        "clf_poly = svm.SVC(kernel='poly', degree = degree, C=1).fit(X_train, y_train)\n",
        "\n",
        "# The performance score with the test data can be seen using model.score(X_test, y_test)\n",
        "clf_poly.score(X_test, y_test)\n",
        "\n",
        "# Using the polynomial Kernel\n",
        "model_poly = clf_poly\n",
        "for number_of_folds in range(3,8):\n",
        "  print(f'K-fold cross validation for K={number_of_folds} folds')\n",
        "  cross_validation(model_poly , number_of_folds)\n",
        "  print('-----------------------\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjkqpMvSzemr",
        "outputId": "7db998a2-7121-4c1e-b5cb-5f8f485c8c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-fold cross validation for K=3 folds\n",
            "Accuracy for each fold\n",
            "   [0.98 1.   0.96]\n",
            "\n",
            "The mean of all K-folds\n",
            "   0.98\n",
            "-----------------------\n",
            "\n",
            "K-fold cross validation for K=4 folds\n",
            "Accuracy for each fold\n",
            "   [0.97368421 0.97368421 0.94594595 0.97297297]\n",
            "\n",
            "The mean of all K-folds\n",
            "   0.9665718349928876\n",
            "-----------------------\n",
            "\n",
            "K-fold cross validation for K=5 folds\n",
            "Accuracy for each fold\n",
            "   [0.96666667 1.         1.         0.96666667 1.        ]\n",
            "\n",
            "The mean of all K-folds\n",
            "   0.9866666666666667\n",
            "-----------------------\n",
            "\n",
            "K-fold cross validation for K=6 folds\n",
            "Accuracy for each fold\n",
            "   [0.96 1.   0.96 0.96 1.   1.  ]\n",
            "\n",
            "The mean of all K-folds\n",
            "   0.98\n",
            "-----------------------\n",
            "\n",
            "K-fold cross validation for K=7 folds\n",
            "Accuracy for each fold\n",
            "   [0.95454545 1.         0.95454545 1.         0.9047619  1.\n",
            " 1.        ]\n",
            "\n",
            "The mean of all K-folds\n",
            "   0.9734075448361164\n",
            "-----------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the previous three descriptions, when the kernel is linear, polynomial of degree 2, and polynomial of degree 3, we can conclude that better performance is achieved by using cross-validation for SVC with a polynomial kernel of degree 2 and K = 5 number of folds. This is evident from the score improvement to 0.9866666666666667 compared to 0.9800000000000001 in both other approaches."
      ],
      "metadata": {
        "id": "qsk6YCin3bZW"
      }
    }
  ]
}